The problem: Modern research paper using domain-specific/technical terms, detailed methodology, complex modeling, that is hard for non-expert and causual readers to follow (long text + hard to understand)

Why is this problem intersting/hard: If a user wants to create a comic traditionally they need to either read and understand the paper -> craft narritive/dialogues -> draw or generates comics based on how he'd like the comic look like; Now we can use `tool-based multimodal`(which is image generator serves as a tool that LLM can use instead a part of it) LLMs to generate outline, scene, dialogues, and image description, and use tools like SD or DALLE to generate comics based on the desc. However, there are problems, specifically in image generateion: 1. Hard to control and change in detail, like text rendering, detail fixing; 2. The characters are not consistent accorss generated images;
With the new technology of truely multimodal models that runs on a single foundation model that takes and output both text and image token, we are achieving more promissing results, we have fine-grained control over the genrated image, and we can achieve a very high consistency with characters accross scene. However there are still difficulties, like the lack of fine texture, creativity in artistical styles in the newer model comparing to pure diffusion based models.

What are we trying to achieve?: We aims to crate a semi-automatic pipeline to create (story rich, good looking, consistant, detailed but easy to understand for causal readers) comics of research papers without the operator having to understand the paper, and a fast speed.

How are we achieving that?: We asked LLMs to read and process the paper, extract the core ideas, approaches, reuslts, etc. And ask it to create a engaging story that tells the main idea through it, and craft each scene and panel (in text), create characters, and finally draw the images. We also test the images by the two approaches, and other tricks like that of generating consistent characters (in one/all model)

What are the takeaways/challengens remain: Although the newer method greatly enhance the understandability/ease-of-read/less error of the image, it lacks the artistical aspect; also, in the new method, some problems still presist, like hard to generate image with overly detailed prompts, sometimes still typos, minor errors that might still reduce the willingness to watch from audiences.